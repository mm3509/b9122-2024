{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture 11\n",
        "\n",
        "Here we use the E-car dataset on car loan applications.\n",
        "\n",
        "IF you're running this on Google Colab, and only then, should you run this cell:"
      ],
      "metadata": {
        "id": "BuXYLTLs7rlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !! Run this on Google Colab only.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "T2lWLSol78F8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the required modules"
      ],
      "metadata": {
        "id": "pn01QLMe8HVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns  # Seaborn is a plotting library derived from matplotlib"
      ],
      "metadata": {
        "id": "2WiD9xJk8Jfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the dataset:"
      ],
      "metadata": {
        "id": "ivf6xuLs8N6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_FILEPATH = \"drive/MyDrive/e_car_data.csv\"\n",
        "df = pd.read_csv(DATA_FILEPATH)"
      ],
      "metadata": {
        "id": "QNfDlC6w8PW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show summary statistics:"
      ],
      "metadata": {
        "id": "MY2wD2c6-rfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "08A2CnnZ-xYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare data for multi-class logistic regression, with three features:"
      ],
      "metadata": {
        "id": "xZ3WWE0d_cJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = df[['tier', 'amount', 'prime']].values\n",
        "\n",
        "x_scaled = preprocessing.scale(x1)\n",
        "\n",
        "apr = df['apr'].values\n",
        "accept = df['accept'].values"
      ],
      "metadata": {
        "id": "N8Xy9IcV_BLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Place loans into 8 unordered classes / bins, depending on their acceptance (1-4 for denied, 5-8 for accepted) and their Annual Percentage Rate (APR, into 4 classes each):"
      ],
      "metadata": {
        "id": "fZybA9898hwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loan_to_bin(accept_value, apr_value):\n",
        "  offset = 0\n",
        "  if accept_value:\n",
        "    offset = 4\n",
        "\n",
        "  if apr_value < 4:\n",
        "    return offset\n",
        "\n",
        "  if apr_value < 6:\n",
        "    return 1 + offset\n",
        "\n",
        "  if apr_value < 8:\n",
        "    return 2 + offset\n",
        "\n",
        "  return 3 + offset"
      ],
      "metadata": {
        "id": "q0Twh5ek8tTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create new labels for the dataset:"
      ],
      "metadata": {
        "id": "WLqgrt7v9KXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = []\n",
        "for i in range(len(apr)):\n",
        "    accept_value = accept[i]\n",
        "    apr_value = apr[i]\n",
        "    bin = loan_to_bin(accept_value, apr_value)\n",
        "    y.append(bin)\n",
        "\n",
        "# Alternative in one-line with a list comprehension (but less readable):\n",
        "# y = [loan_to_bin(accept[i], apr[i]) for i in range(len(apr))]"
      ],
      "metadata": {
        "id": "5QkZwo3V93D-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data into train and test (90/10 split):\n"
      ],
      "metadata": {
        "id": "cvb9gygP-bfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.1)"
      ],
      "metadata": {
        "id": "-W8o9MLJ-dKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model. The argument `multi_class` is now redundant: when the outcomes have 3 or more classes, ScitKit-Learn understands that you want to run a multinomial model, and started showing a warning. I prefer to have the argument and the warning, because the code is more readable in that we want multinomial regression."
      ],
      "metadata": {
        "id": "5K7qOFFK-hfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(multi_class='multinomial').fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "0-nMtrgm-i1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict the values in the test set, using the built-in function `.predict()`, and evaluate accuracy:"
      ],
      "metadata": {
        "id": "7X_zG6yu-lhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_predict = model.predict(x_test)\n",
        "accuracy = metrics.accuracy_score(y_test, y_test_predict)\n",
        "print (\"Multi-class logistic regression Accuracy Score on Test Set:\", accuracy)"
      ],
      "metadata": {
        "id": "qkTMzOfhAbYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the \"confusion\" matrix, or predicted labels versus true labels"
      ],
      "metadata": {
        "id": "8FkjLCflAslI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = model.predict(x_train)\n",
        "mat = metrics.confusion_matrix(y_train, predicted)\n",
        "sns.heatmap(mat.T,\n",
        "            square = True,\n",
        "            annot=True,\n",
        "            fmt = \"d\",\n",
        "            )\n",
        "plt.xlabel(\"true labels\")\n",
        "plt.ylabel(\"predicted label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RPFu96K-Auaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: run the previous cells again, without scaling\n",
        "\n",
        "Go back to a previous cell and remove or comment the line that scales the features. How does the multi-class logistic regression behave now? Why?"
      ],
      "metadata": {
        "id": "roOVPyDguW3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perceptron\n",
        "\n",
        "Now let's fit a perceptron on the same dataset, using a single variable for loan approved or not.\n",
        "\n",
        "Import the Perceptron model from ScitKit-Learn:"
      ],
      "metadata": {
        "id": "4TiBabp9EF4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Perceptron"
      ],
      "metadata": {
        "id": "9uKZqrZ3EMud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the outcome and the features:"
      ],
      "metadata": {
        "id": "H-Inm5AwEWtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['accept'].values\n",
        "columns = ['tier',\n",
        "           'amount',\n",
        "           'apr',\n",
        "           'prime',\n",
        "           'fico',\n",
        "           'competition apr',\n",
        "           'partner bin']\n",
        "x2 = df[columns].values"
      ],
      "metadata": {
        "id": "TX9QjUY4ERb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize the data, to help with convergence, and split into training set and validation set:"
      ],
      "metadata": {
        "id": "R9EHC19HEqt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x2_scaled = preprocessing.scale(x2)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x2_scaled, y, test_size=0.1)"
      ],
      "metadata": {
        "id": "CWSReyJHEtk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a perceptron with a learning rate:"
      ],
      "metadata": {
        "id": "jndWvIPVIGSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pmodel = Perceptron(eta0=0.1)\n",
        "pmodel.fit(x_train, y_train)\n",
        "y_test_predict = pmodel.predict(x_test)\n",
        "accuracy = metrics.accuracy_score(y_test, y_test_predict)\n",
        "print(\"Perceptron Accuracy Score on Test Set: %.5f\" % accuracy)"
      ],
      "metadata": {
        "id": "cKc9O6G8FB-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-layer perceptron\n",
        "\n",
        "We'll use a model from SciKit-Learn, which already has all we need (e.g., cross-entropy loss function). We define two hidden layers, with 64 and 32 neurons, and fit it to data. Notice that the accuracy has impoved to around 80%."
      ],
      "metadata": {
        "id": "4zA25wb5LaMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(64, 32),\n",
        "                    activation=\"logistic\",\n",
        "                    max_iter=1000,\n",
        "                    random_state=42)\n",
        "\n",
        "mlp.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = mlp.predict(x_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy of multi-layer perceptron on test data: %.5f\" %\n",
        "      accuracy)"
      ],
      "metadata": {
        "id": "CW7tvU76LjSs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}